import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import random
import re
import json
import os

import concurrent.futures
import socket
from urllib.parse import urljoin

try:
    from pyngrok import ngrok  # å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹ç”¨
except ImportError:
    ngrok = None

# page config
st.set_page_config(page_title="ç¤¾åŠ´å£«éå»å•ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼", page_icon="ğŸ“")

st.title("ğŸ“ ç¤¾åŠ´å£«éå»å• ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ & ã‚«ãƒ¼ãƒ‰ä½œæˆ")
st.markdown(
    "æŒ‡å®šã•ã‚ŒãŸéå»å•ãƒšãƒ¼ã‚¸ã®ã€Œå•é¡Œã€ã¨ã€Œè§£èª¬ã€ã‚’å–å¾—ã—ã€AIã§ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã™ã€‚"
)

# å®šæ•°å®šç¾©
SAVE_FILE = "sharousi_data.json"


def load_data_with_retry(filepath, retries=3, delay=0.5):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€éš›ã€ç«¶åˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã‚‰ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹é–¢æ•°
    """
    for i in range(retries):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, OSError, PermissionError):
            if i < retries - 1:
                time.sleep(delay)
            else:
                return []
    return []


# Sidebar
st.sidebar.markdown("## ğŸ“Š åé›†çŠ¶æ³")
if os.path.exists(SAVE_FILE):
    try:
        d = load_data_with_retry(SAVE_FILE)
        st.sidebar.metric("ç·ã‚«ãƒ¼ãƒ‰æ•°", f"{len(d)} æš")

        # Breakdown
        subjects = {}
        for x in d:
            s = x.get("subject", "ä¸æ˜")
            subjects[s] = subjects.get(s, 0) + 1

        if subjects:
            st.sidebar.markdown("### ç§‘ç›®åˆ¥")
            st.sidebar.bar_chart(subjects)
    except Exception:
        st.sidebar.caption("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
else:
    st.sidebar.caption("ãƒ‡ãƒ¼ã‚¿ãªã—")

st.sidebar.markdown("---")

# ã‚¹ãƒãƒ›æ¥ç¶šç”¨æƒ…å ±è¡¨ç¤º
try:
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    s.connect(("8.8.8.8", 80))
    ip_addr = s.getsockname()[0]
    s.close()
    st.sidebar.markdown("### ğŸ“± ã‚¹ãƒãƒ›ã§è¦‹ã‚‹ã¨ã")
    st.sidebar.info(f"ã‚¹ãƒãƒ›ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ä»¥ä¸‹ã«ã‚¢ã‚¯ã‚»ã‚¹:\n\nhttp://{ip_addr}:8501")

    # QRã‚³ãƒ¼ãƒ‰è¡¨ç¤º
    qr_url = f"https://api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://{ip_addr}:8501"
    st.sidebar.image(qr_url, caption="ã‚¹ãƒãƒ›ã§ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦æ¥ç¶š")

    st.sidebar.caption("â€»åŒã˜Wi-Fiã«æ¥ç¶šã—ã¦ãã ã•ã„")
except Exception:
    pass

st.sidebar.markdown("---")

# --- å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹æ©Ÿèƒ½ (ngrok) ---
st.sidebar.markdown("### ğŸŒ å±‹å¤–ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹")
with st.sidebar.expander("å¤–éƒ¨å…¬é–‹è¨­å®š (ngrok)"):
    st.caption("å¤–å‡ºå…ˆã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã«ã¯ngrokã®è¨­å®šãŒå¿…è¦ã§ã™ã€‚")
    st.markdown(
        "[ngrokå…¬å¼ã‚µã‚¤ãƒˆ](https://dashboard.ngrok.com/get-started/your-authtoken) ã§Authtokenã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚"
    )

    # Tokenä¿å­˜ç”¨ãƒ•ã‚¡ã‚¤ãƒ«
    TOKEN_FILE = ".ngrok_token"
    saved_token = ""
    if os.path.exists(TOKEN_FILE):
        with open(TOKEN_FILE, "r") as f:
            saved_token = f.read().strip()

    auth_token = st.text_input("Authtokenã‚’å…¥åŠ›", value=saved_token, type="password")

    if st.button("è¨­å®šã‚’ä¿å­˜ & æ¥ç¶šé–‹å§‹"):
        if auth_token:
            # Tokenä¿å­˜
            with open(TOKEN_FILE, "w") as f:
                f.write(auth_token)

            try:
                # ngrokè¨­å®š
                if ngrok:
                    ngrok.set_auth_token(auth_token)

                    # æ—¢å­˜ã®ãƒˆãƒ³ãƒãƒ«ã‚’ç¢ºèªã—ã¦é–‰ã˜ã‚‹ (å†èµ·å‹•æ™‚ç”¨)
                    tunnels = ngrok.get_tunnels()
                    for t in tunnels:
                        ngrok.disconnect(t.public_url)

                    # ãƒˆãƒ³ãƒãƒ«é–‹å§‹ (ãƒãƒ¼ãƒˆ8501)
                    public_url = ngrok.connect(8501).public_url
                    st.session_state["ngrok_url"] = public_url
                    st.success("æ¥ç¶šã—ã¾ã—ãŸï¼")
                else:
                    st.error(
                        "ç¾åœ¨ã“ã®ç’°å¢ƒã§ã¯ngrokãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“(requirements.txtã‚’ç¢ºèªã—ã¦ãã ã•ã„)"
                    )

            except Exception as e:
                st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.warning("Authtokenã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    # æ¥ç¶šæ¸ˆã¿ãªã‚‰QRè¡¨ç¤º
    if "ngrok_url" in st.session_state:
        pub_url = st.session_state["ngrok_url"]
        st.success("ğŸŒ å…¬é–‹ä¸­")
        st.code(pub_url)

        # QRã‚³ãƒ¼ãƒ‰
        qr_ngrok = (
            f"https://api.qrserver.com/v1/create-qr-code/?size=150x150&data={pub_url}"
        )
        st.image(qr_ngrok, caption="å¤–å‡ºå…ˆã‹ã‚‰ã‚¹ã‚­ãƒ£ãƒ³")

        if st.button("åˆ‡æ–­ã™ã‚‹"):
            if ngrok:
                ngrok.kill()
            del st.session_state["ngrok_url"]
            st.rerun()

st.sidebar.markdown("---")


target_url = st.text_input(
    "å¯¾è±¡URL (ä¾‹: https://sharousi-kakomon.com/data/1)",
    "https://sharousi-kakomon.com/data/1",
)

st.sidebar.markdown("---")
max_count = st.sidebar.slider(
    "å–å¾—ã™ã‚‹å•é¡Œæ•° (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿æœ‰åŠ¹)",
    1,
    100,
    10,
    help="ã€Œä½œæˆé–‹å§‹ã€ãƒœã‚¿ãƒ³ã§ã®å®Ÿè¡Œæ™‚ã®ã¿é©ç”¨ã•ã‚Œã¾ã™ã€‚å…¨è‡ªå‹•ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã§ã¯ç„¡è¦–ã•ã‚Œã¾ã™ï¼ˆç„¡åˆ¶é™ï¼‰ã€‚",
)
sleep_min = st.sidebar.slider("å¾…æ©Ÿæ™‚é–“(æœ€å°)", 2.0, 5.0, 3.0)
sleep_max = st.sidebar.slider("å¾…æ©Ÿæ™‚é–“(æœ€å¤§)", 5.0, 15.0, 6.0)


def parse_html_text(element):
    """
    HTMLè¦ç´ ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã€èµ¤æ–‡å­—ãƒ»ç·‘æ–‡å­—ã‚’Streamlitã®Markdownè¨˜æ³•ã«å¤‰æ›ã™ã‚‹
    """
    if not element:
        return ""

    text = ""
    for child in element.contents:
        if child.name is None:  # Text Node
            text += child.string if child.string else ""
        elif child.name == "br":
            text += "\n"
        else:
            # Recursive parse
            inner_text = parse_html_text(child)

            # Check color
            color = ""
            cls = child.get("class", [])
            if isinstance(cls, str):
                cls = [cls]

            style = child.get("style", "").lower()

            # èµ¤ãƒ»ç·‘ã®åˆ¤å®š (ã‚¯ãƒ©ã‚¹åã‚„ã‚¹ã‚¿ã‚¤ãƒ«)
            # åˆ¤æ˜ã—ã¦ã„ã‚‹ã‚¯ãƒ©ã‚¹: clr2 -> èµ¤
            styles_str = style.lower()
            classes_set = set([c.lower() for c in cls])

            if (
                "clr2" in classes_set
                or any("red" in c for c in classes_set)
                or "color:red" in styles_str
                or "color: red" in styles_str
                or "#ff0000" in styles_str
            ):
                color = "red"
            elif (
                any("green" in c for c in classes_set)
                or "color:green" in styles_str
                or "color: green" in styles_str
            ):
                color = "green"

            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆï¼ˆMarkdownã®ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ç­‰ã§åˆ¤å®šï¼‰ã€è‰²æŒ‡å®šã§å›²ã‚€ã¨å´©ã‚Œã‚‹ã®ã§ã‚¹ã‚­ãƒƒãƒ—
            if "| --- |" in inner_text or "\n| " in inner_text:
                color = ""  # å¼·åˆ¶çš„ã«ç„¡åŠ¹åŒ–

            if color:
                text += f":{color}[{inner_text}]"
            else:
                text += inner_text

    return text


def get_explanation(session, q_id, referer_url):
    """APIã‚’å©ã„ã¦è§£èª¬ã‚’å–å¾—ã™ã‚‹"""
    api_url = "https://sharousi-kakomon.com/q/check_q_a.php"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Content-Type": "application/x-www-form-urlencoded;charset=UTF-8",
        "X-Requested-With": "XMLHttpRequest",
        "Origin": "https://sharousi-kakomon.com",
        "Referer": referer_url,
    }
    data = {"q": q_id, "a": "1"}  # 1=Maru, 0=Batsu (Either returns explanation)

    try:
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå»¶é•·
        resp = session.post(api_url, headers=headers, data=data, timeout=15)
        if resp.status_code == 200:
            # Response is HTML snippet
            soup = BeautifulSoup(resp.text, "html.parser")
            kaisetsu_div = soup.find("div", class_="kaisetu")
            joubun_div = soup.find("div", class_="joubun")
            point_div = soup.find("div", class_="point")

            # ä½•ã‚‚å–å¾—ã§ããªã‹ã£ãŸå ´åˆã¯ã€APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¸æ­£ã®å¯èƒ½æ€§ãŒã‚ã‚‹
            if not kaisetsu_div and not joubun_div and not point_div:
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ¥µç«¯ã«çŸ­ã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼æ‰±ã„
                if len(resp.text) < 50:
                    return "APIã‚¨ãƒ©ãƒ¼: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¸æ­£(Empty)", "", ""
                # ååˆ†ãªé•·ã•ãŒã‚ã‚‹ãªã‚‰ã€Œè§£èª¬ãªã—ã€ã‹ã‚‚ã—ã‚Œãªã„ãŒã€å¿µã®ãŸã‚

            kaisetsu_text = (
                parse_html_text(kaisetsu_div).strip()
                if kaisetsu_div
                else "è§£èª¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
            )
            joubun_text = parse_html_text(joubun_div).strip() if joubun_div else ""
            point_text = parse_html_text(point_div).strip() if point_div else ""

            return kaisetsu_text, joubun_text, point_text
        else:
            return f"APIã‚¨ãƒ©ãƒ¼: {resp.status_code}", "", ""
    except Exception as e:
        return f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}", "", ""


def generate_rewrite(question, explanation, article="", point=""):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›:
    è¡¨é¢: ãƒã‚¤ãƒ³ãƒˆ + è§£èª¬ + æ¡æ–‡ (è¦ç´„ãªã—)
    è£é¢: ã‚½ãƒ¼ã‚¹URL (å‘¼ã³å‡ºã—å…ƒã§è¨­å®š)
    """

    # AIã‚’ä½¿ç”¨ã›ãšã€ãã®ã¾ã¾çµåˆã—ã¦è¿”ã™
    components = []

    # ãƒã‚¤ãƒ³ãƒˆ
    if point:
        components.append(f"ã€ãƒã‚¤ãƒ³ãƒˆã€‘\n{point}")

    # è§£èª¬
    components.append(f"ã€è§£èª¬ã€‘\n{explanation}")

    # æ¡æ–‡
    if article:
        components.append(f"ã€æ¡æ–‡ã€‘\n{article}")

    front_text = "\n\n---\n".join(components)

    return front_text, explanation


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
tab1, tab2, tab3 = st.tabs(
    ["ğŸš€ é€šå¸¸ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°", "ğŸ“‚ ä¿å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª", "ğŸ¤– å…¨è‡ªå‹•ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼"]
)

# ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
# SAVE_FILE ã¯ä¸Šéƒ¨ã§å®šç¾©æ¸ˆã¿

bulk_progress_file = "bulk_progress.json"

with tab3:
    st.header("ğŸ¤– å…¨è‡ªå‹•ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ (å…¨å•å–å¾—)")
    st.warning(
        "âš ï¸ ã“ã®æ©Ÿèƒ½ã¯ã‚µã‚¤ãƒˆå†…ã®å…¨å•é¡Œã‚’é †ç•ªã«å–å¾—ã—ã¾ã™ã€‚éå¸¸ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚"
    )

    # å‰å›é€²æ—ã®èª­ã¿è¾¼ã¿
    default_subject = 1
    default_page = 1
    if os.path.exists(bulk_progress_file):
        try:
            with open(bulk_progress_file, "r", encoding="utf-8") as f:
                prog = json.load(f)
                default_subject = prog.get("subject", 1)
                default_page = prog.get("page", 1)
        except Exception:
            pass

    col1, col2 = st.columns(2)
    with col1:
        start_subject = st.number_input("é–‹å§‹ç§‘ç›®ID (1-10)", 1, 10, default_subject)
        start_page = st.number_input("é–‹å§‹ãƒšãƒ¼ã‚¸", 1, 100, default_page)
    with col2:
        # ãƒ©ãƒ³ãƒ€ãƒ å¾…æ©Ÿã®å¹…è¨­å®š
        wait_min = st.number_input("å¾…æ©Ÿ(æœ€å°)ç§’", 3.0, 10.0, 5.0)
        wait_max = st.number_input("å¾…æ©Ÿ(æœ€å¤§)ç§’", 5.0, 30.0, 10.0)

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    stop_every_subject = st.checkbox("1ç§‘ç›®å®Œäº†ã”ã¨ã«ä¸€æ™‚åœæ­¢ã™ã‚‹ (æ¨å¥¨)", value=True)

    # åœæ­¢ãƒœã‚¿ãƒ³ç”¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    stop_placeholder = st.empty()

    # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
    status_text = st.empty()
    progress_bar_bulk = st.progress(0)

    # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ (è¿½è¨˜) - ãƒ«ãƒ¼ãƒ—ã®å¤–
    st.markdown("---")
    with st.expander("âš ï¸ ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚»ãƒƒãƒˆï¼ˆæœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™å ´åˆï¼‰"):
        st.warning(
            "ã€Œå…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã€ã‚’æŠ¼ã™ã¨ã€ã“ã‚Œã¾ã§ã«ä¿å­˜ã—ãŸã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã¨é€²æ—ãŒã™ã¹ã¦æ¶ˆãˆã¾ã™ã€‚"
        )
        if st.button("ğŸ—‘ï¸ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¦ãƒªã‚»ãƒƒãƒˆ"):
            if os.path.exists(SAVE_FILE):
                os.remove(SAVE_FILE)
            if os.path.exists(bulk_progress_file):
                os.remove(bulk_progress_file)

            st.cache_data.clear()
            st.success("ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            time.sleep(1)
            st.rerun()

    # ãƒ‡ãƒ¼ã‚¿ä¿®å¾©ãƒœã‚¿ãƒ³
    st.markdown("---")
    with st.expander("ğŸ› ï¸ ãƒ‡ãƒ¼ã‚¿ä¿®å¾©ï¼ˆè§£èª¬å–å¾—å¤±æ•—ãªã©ã‚’ãƒªãƒˆãƒ©ã‚¤ï¼‰"):
        st.info(
            "AIç”Ÿæˆã‚¨ãƒ©ãƒ¼ãªã©ã§è¡¨é¢ãŒæ­£ã—ãä¿å­˜ã•ã‚Œãªã‹ã£ãŸã‚«ãƒ¼ãƒ‰ã‚’ã€å†åº¦ã‚µã‚¤ãƒˆã‹ã‚‰å•é¡Œæ–‡ã‚’å–å¾—ã—ã¦ä¿®æ­£ã—ã¾ã™ã€‚"
        )
        if st.button("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ã®ä¿®å¾©ã‚’é–‹å§‹"):
            if os.path.exists(SAVE_FILE):
                try:
                    data = load_data_with_retry(SAVE_FILE)

                    count_fixed = 0
                    count_unfixable = 0
                    repair_bar = st.progress(0)
                    status_repair = st.empty()

                    session_repair = requests.Session()
                    session_repair.headers.update(
                        {
                            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                        }
                    )

                    # ä¿®å¾©ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
                    def is_broken(card):
                        front = card.get("front", "")
                        if not front:
                            return True

                        # 1. æ—¢çŸ¥ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                        error_keywords = [
                            "è§£èª¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                            "è§£èª¬æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ",  # è¿½åŠ 
                            "è§£èª¬å–å¾—å¤±æ•—",
                            "APIã‚¨ãƒ©ãƒ¼",
                            "é€šä¿¡ã‚¨ãƒ©ãƒ¼",
                        ]
                        if any(k in front for k in error_keywords):
                            return True

                        # 2. è§£èª¬ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãªã„
                        if "ã€è§£èª¬ã€‘" not in front:
                            return True

                        # 3. è§£èª¬ã®ä¸­èº«ãŒç©ºï¼ˆã€è§£èª¬ã€‘ã®ç›´å¾Œã«ã€æ¡æ–‡ã€‘ãŒæ¥ã‚‹ã€ã¾ãŸã¯æœ«å°¾ï¼‰
                        try:
                            parts = front.split("ã€è§£èª¬ã€‘")
                            if len(parts) > 1:
                                after_kaisetsu = parts[1]
                                # ã€æ¡æ–‡ã€‘ãŒã‚ã‚Œã°ãã“ã¾ã§ã€ãªã‘ã‚Œã°æœ€å¾Œã¾ã§
                                if "ã€æ¡æ–‡ã€‘" in after_kaisetsu:
                                    content = after_kaisetsu.split("ã€æ¡æ–‡ã€‘")[0]
                                else:
                                    content = after_kaisetsu

                                # ç©ºç™½ã‚’é™¤ã„ã¦ç©ºã£ã½ãªã‚‰ã‚¢ã‚¦ãƒˆ
                                if not content.strip():
                                    return True
                        except Exception:
                            pass

                        return False

                    # ä¿®å¾©å¯¾è±¡ã‚’ç‰¹å®š
                    targets = [i for i, c in enumerate(data) if is_broken(c)]

                    if not targets:
                        st.success("ä¿®å¾©ãŒå¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    else:
                        st.info(
                            f"{len(targets)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸¦åˆ—ä¿®å¾©ã—ã¦ã„ã¾ã™... (æœ€å¤§5ä¸¦åˆ—)"
                        )

                        repair_bar = st.progress(0)
                        status_repair = st.empty()

                        count_fixed = 0
                        count_unfixable = 0
                        count_processed = 0
                        total_targets = len(targets)

                        def repair_single_card(target_info):
                            """ä¸¦åˆ—å®Ÿè¡Œç”¨é–¢æ•°"""
                            idx, card = target_info
                            url = card.get("source")
                            if not url:
                                return idx, None, "URLãªã—", False, False

                            local_session = requests.Session()
                            local_session.headers.update(
                                {
                                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                                }
                            )

                            max_retries = 5
                            for attempt in range(max_retries):
                                try:
                                    time.sleep(random.uniform(2.0, 5.0))
                                    r = local_session.get(url, timeout=15)
                                    if r.status_code == 200:
                                        soup_r = BeautifulSoup(r.text, "html.parser")
                                        q_div = soup_r.find("div", class_="q_body")
                                        question_text = (
                                            q_div.get_text(strip=True) if q_div else ""
                                        )

                                        q_id = None
                                        inputs = soup_r.find_all("input", onclick=True)
                                        for inp in inputs:
                                            match = re.search(
                                                r"answer\((\d+),", inp["onclick"]
                                            )
                                            if match:
                                                q_id = match.group(1)
                                                break

                                        if q_id:
                                            (
                                                explanation_text,
                                                article_text,
                                                point_text,
                                            ) = get_explanation(
                                                local_session, q_id, url
                                            )

                                            if (
                                                "APIã‚¨ãƒ©ãƒ¼" in explanation_text
                                                or "é€šä¿¡ã‚¨ãƒ©ãƒ¼" in explanation_text
                                            ):
                                                continue

                                            is_missing_msg = (
                                                "è§£èª¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                                                in explanation_text
                                                or "è§£èª¬æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                                                in explanation_text
                                                or "è§£èª¬å–å¾—å¤±æ•—" in explanation_text
                                            )
                                            has_sub_info = bool(
                                                article_text or point_text
                                            )

                                            final_exp = explanation_text
                                            if is_missing_msg and not has_sub_info:
                                                final_exp = "ï¼ˆå…¬å¼ã«è§£èª¬æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"

                                            new_front, _ = generate_rewrite(
                                                question_text,
                                                final_exp,
                                                article_text,
                                                point_text,
                                            )
                                            card["front"] = new_front

                                            is_unfixable = (
                                                is_missing_msg and not has_sub_info
                                            )
                                            return (
                                                idx,
                                                card,
                                                f"å®Œäº†: {url}",
                                                True,
                                                is_unfixable,
                                            )
                                        else:
                                            pass
                                    elif r.status_code == 404:
                                        card["front"] += "\n(ãƒšãƒ¼ã‚¸ãŒå‰Šé™¤ã•ã‚Œã¦ã„ã¾ã™)"
                                        return idx, card, "404 Not Found", True, True

                                except Exception:
                                    time.sleep(1)

                            return idx, None, f"å¤±æ•—: {url}", False, False

                        with concurrent.futures.ThreadPoolExecutor(
                            max_workers=5
                        ) as executor:
                            target_infos = [(i, data[i].copy()) for i in targets]
                            future_to_idx = {
                                executor.submit(repair_single_card, info): info[0]
                                for info in target_infos
                            }

                            for future in concurrent.futures.as_completed(
                                future_to_idx
                            ):
                                idx, new_card, msg, success, unfixable = future.result()
                                count_processed += 1
                                repair_bar.progress(count_processed / total_targets)
                                status_repair.write(
                                    f"ä¿®å¾©ä¸­... {count_processed}/{total_targets} (æˆåŠŸ: {count_fixed}, è§£èª¬ãªã—: {count_unfixable})"
                                )

                                if success:
                                    if new_card:
                                        data[idx] = new_card
                                    if unfixable:
                                        count_unfixable += 1
                                    else:
                                        count_fixed += 1

                                if count_processed % 10 == 0:
                                    try:
                                        with open(
                                            SAVE_FILE, "w", encoding="utf-8"
                                        ) as f:
                                            json.dump(
                                                data, f, ensure_ascii=False, indent=2
                                            )
                                    except Exception:
                                        pass

                        with open(SAVE_FILE, "w", encoding="utf-8") as f:
                            json.dump(data, f, ensure_ascii=False, indent=2)

                        st.success(
                            f"ä¿®å¾©å®Œäº†ï¼ {count_fixed} ä»¶ã‚’ä¿®æ­£ã€{count_unfixable} ä»¶ã‚’è§£èª¬ãªã—ã¨ã—ã¦ãƒãƒ¼ã‚¯ã—ã¾ã—ãŸã€‚"
                        )
                        time.sleep(2)
                        st.rerun()

                except Exception as e:
                    st.error(f"ä¿®å¾©ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # å…¨ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒœã‚¿ãƒ³ï¼ˆè¡¨å½¢å¼é©ç”¨ãªã©ï¼‰
    st.markdown("---")
    with st.expander("ğŸ”„ å…¨ãƒ‡ãƒ¼ã‚¿ã®å¼·åˆ¶æ›´æ–° (è¡¨å½¢å¼ã®é©ç”¨ãªã©)"):
        st.warning(
            "ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦ä¸Šæ›¸ãã—ã¾ã™ã€‚å®Œäº†ã¾ã§éå¸¸ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚é€”ä¸­ã§æ­¢ã‚ã‚‹å ´åˆã¯ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã¦ãã ã•ã„ã€‚"
        )
        if st.button("ğŸš¨ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ãƒ»æ›´æ–°ã™ã‚‹"):
            if os.path.exists(SAVE_FILE):
                try:
                    data = load_data_with_retry(SAVE_FILE)

                    # å…¨ä»¶å¯¾è±¡
                    targets = list(range(len(data)))

                    count_updated = 0
                    update_bar = st.progress(0)
                    status_update = st.empty()

                    session_update = requests.Session()
                    session_update.headers.update(
                        {
                            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                        }
                    )

                    for idx, i in enumerate(targets):
                        card = data[i]
                        url = card.get("source")
                        if url:
                            status_update.write(
                                f"æ›´æ–°ä¸­ ({idx + 1}/{len(targets)}): {url}"
                            )
                            # ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯
                            max_retries = 3
                            for attempt in range(max_retries):
                                try:
                                    r = session_update.get(url, timeout=10)
                                    if r.status_code == 200:
                                        soup_r = BeautifulSoup(r.text, "html.parser")
                                        q_div = soup_r.find("div", class_="q_body")
                                        question_text = (
                                            q_div.get_text(strip=True) if q_div else ""
                                        )

                                        # q_id ã‚’å–å¾—
                                        q_id = None
                                        inputs = soup_r.find_all("input", onclick=True)
                                        for inp in inputs:
                                            match = re.search(
                                                r"answer\((\d+),", inp["onclick"]
                                            )
                                            if match:
                                                q_id = match.group(1)
                                                break

                                        if q_id:
                                            # è§£èª¬ã‚’å†å–å¾— (ã“ã“ã§æ–°ã—ã„Markdownå¤‰æ›ãŒé©ç”¨ã•ã‚Œã‚‹)
                                            (
                                                explanation_text,
                                                article_text,
                                                point_text,
                                            ) = get_explanation(
                                                session_update, q_id, url
                                            )

                                            # æˆåŠŸã—ãŸã‚‰æ›´æ–°
                                            if "è§£èª¬å–å¾—å¤±æ•—" not in explanation_text:
                                                front, _ = generate_rewrite(
                                                    question_text,
                                                    explanation_text,  # Markdownå¤‰æ›æ¸ˆã¿
                                                    article_text,
                                                    point_text,
                                                )
                                                data[i]["front"] = front
                                                count_updated += 1
                                                break

                                    elif r.status_code == 404:
                                        break

                                except Exception:
                                    # print(f"Error attempt {attempt}: {e}")
                                    time.sleep(1)

                        update_bar.progress((idx + 1) / len(targets))

                        # ä¸­é–“ä¿å­˜ (10ä»¶ã”ã¨)
                        if (idx + 1) % 10 == 0:
                            try:
                                with open(SAVE_FILE, "w", encoding="utf-8") as f:
                                    json.dump(data, f, ensure_ascii=False, indent=2)
                            except Exception:
                                pass

                        time.sleep(0.5)  # è² è·è»½æ¸›

                    # æœ€çµ‚ä¿å­˜
                    with open(SAVE_FILE, "w", encoding="utf-8") as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)

                    st.success(
                        f"å…¨ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼ ({count_updated} ä»¶æ›´æ–°)"
                    )
                    time.sleep(2)
                    st.rerun()

                except Exception as e:
                    st.error(f"æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    if st.button("å…¨è‡ªå‹•ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹", key="bulk_start"):
        session = requests.Session()
        session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
        )

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        all_cards = []
        if os.path.exists(SAVE_FILE):
            try:
                all_cards = load_data_with_retry(SAVE_FILE)
            except Exception:
                pass

        existing_urls = set([c.get("source") for c in all_cards])

        stop_button = stop_placeholder.button("â›” åœæ­¢ã™ã‚‹", key="stop_bulk")

        try:
            # APIã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–
            api_error_count = 0

            # ç§‘ç›®ãƒ«ãƒ¼ãƒ— (1~10: åŠ´åƒåŸºæº–æ³•, å®‰è¡›æ³• etc...)
            for subject_id in range(start_subject, 11):
                page = start_page if subject_id == start_subject else 1

                while True:  # ãƒšãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ—
                    # é€²æ—ä¿å­˜
                    try:
                        with open(bulk_progress_file, "w", encoding="utf-8") as f:
                            json.dump({"subject": subject_id, "page": page}, f)
                    except Exception:
                        pass

                    list_url = (
                        f"https://sharousi-kakomon.com/data/{subject_id}?page={page}"
                    )
                    status_text.text(f"å·¡å›ä¸­... ç§‘ç›®ID: {subject_id}, ãƒšãƒ¼ã‚¸: {page}")

                    # ãƒªã‚¹ãƒˆãƒšãƒ¼ã‚¸å–å¾—
                    resp = session.get(list_url)
                    if resp.status_code != 200:
                        st.error(f"ãƒšãƒ¼ã‚¸å–å¾—ã‚¨ãƒ©ãƒ¼: {list_url}")
                        break

                    soup = BeautifulSoup(resp.text, "html.parser")

                    # ç§‘ç›®å
                    page_title = (
                        soup.title.get_text(strip=True) if soup.title else "ä¸æ˜"
                    )
                    subject_name = page_title.split("-")[0]

                    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
                    rows = soup.find_all("tr")
                    page_items = []
                    for row in rows:
                        cols = row.find_all("td")
                        if len(cols) >= 3:
                            level_text = cols[2].get_text(strip=True)
                            link_tag = row.find("a", href=re.compile(r"/q/\d+"))
                            if link_tag:
                                href = link_tag.get("href")
                                full_url = urljoin(list_url, href)
                                if full_url not in existing_urls:
                                    page_items.append(
                                        {
                                            "url": full_url,
                                            "level": level_text,
                                            "subject": subject_name,
                                        }
                                    )

                    if not page_items:
                        # å•é¡ŒãŒè¦‹ã¤ã‹ã‚‰ãªã„ = ãƒšãƒ¼ã‚¸åˆ‡ã‚Œã®å¯èƒ½æ€§
                        status_text.write(
                            f"ç§‘ç›®ID {subject_id} ã®ãƒšãƒ¼ã‚¸ {page} ã«å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¬¡ã®ç§‘ç›®ã¸ç§»å‹•ã—ã¾ã™ã€‚"
                        )
                        break

                    # å„å•é¡Œã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
                    for i, item in enumerate(page_items):
                        # ãƒ©ãƒ³ãƒ€ãƒ å¾…æ©Ÿ (Botå¯¾ç­–)
                        sleep_time = random.uniform(wait_min, wait_max)
                        status_text.info(f"å¾…æ©Ÿä¸­... {sleep_time:.1f}ç§’ (Botå›é¿ç”¨)")
                        time.sleep(sleep_time)

                        full_link = item["url"]
                        status_text.write(
                            f"[{subject_name}] P.{page} ({i + 1}/{len(page_items)}) å–å¾—ä¸­"
                        )

                        # è©³ç´°ãƒšãƒ¼ã‚¸
                        try:
                            q_resp = session.get(full_link)
                            q_soup = BeautifulSoup(q_resp.text, "html.parser")

                            q_div = q_soup.find("div", class_="q_body")
                            question_text = (
                                q_div.get_text(strip=True) if q_div else "å–å¾—å¤±æ•—"
                            )

                            q_id = None
                            inputs = q_soup.find_all("input", onclick=True)
                            for inp in inputs:
                                match = re.search(r"answer\((\d+),", inp["onclick"])
                                if match:
                                    q_id = match.group(1)
                                    break

                            explanation_text = "è§£èª¬å–å¾—å¤±æ•—"
                            article_text = ""
                            point_text = ""

                            if q_id:
                                explanation_text, article_text, point_text = (
                                    get_explanation(session, q_id, full_link)
                                )

                            # AIãªã—ã€ç›´æ¥çµåˆ
                            front, _ = generate_rewrite(
                                question_text,
                                explanation_text,
                                article_text,
                                point_text,
                            )
                            # è£é¢ã¯ã‚½ãƒ¼ã‚¹URL
                            back = full_link

                            new_card = {
                                "front": front,
                                "back": back,
                                "source": full_link,
                                "subject": item["subject"],
                                "level": item["level"],
                            }
                            # ä¿å­˜ (ä»–ãƒ—ãƒ­ã‚»ã‚¹ã§ã®å¤‰æ›´ã‚’åæ˜ ã™ã‚‹ãŸã‚ã€éƒ½åº¦èª­ã¿è¾¼ã‚“ã§ä¿å­˜)
                            try:
                                current_data = load_data_with_retry(SAVE_FILE)
                                current_data.append(new_card)
                                with open(SAVE_FILE, "w", encoding="utf-8") as f:
                                    json.dump(
                                        current_data, f, ensure_ascii=False, indent=2
                                    )
                                # ãƒ¡ãƒ¢ãƒªä¸Šã®ãƒªã‚¹ãƒˆã‚‚æ›´æ–°(å¿µã®ãŸã‚)
                                all_cards = current_data
                            except Exception as e:
                                st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

                        except Exception as e:
                            st.write(f"ã‚¨ãƒ©ãƒ¼ã‚¹ã‚­ãƒƒãƒ—: {e}")
                            continue

                    # æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸
                    next_link = soup.find("a", string=re.compile("æ¬¡ã¸"))
                    if not next_link:
                        next_link = soup.find("a", href=re.compile(f"page={page + 1}"))

                    if not next_link:
                        break

                    page += 1
                    time.sleep(random.uniform(2.0, 4.0))

                # ç§‘ç›®ãƒ«ãƒ¼ãƒ—çµ‚ã‚ã‚Š
                if stop_every_subject:
                    st.warning(
                        f"âœ… ç§‘ç›®ID {subject_id} ã®å…¨ãƒšãƒ¼ã‚¸å–å¾—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ã€Œ1ç§‘ç›®ã”ã¨ã«ä¸€æ™‚åœæ­¢ã€è¨­å®šã®ãŸã‚ã€ã“ã“ã§ã‚¹ãƒˆãƒƒãƒ—ã—ã¾ã™ã€‚ç¶šãã¯ ID {subject_id + 1} ã‹ã‚‰é–‹å§‹ã—ã¦ãã ã•ã„ã€‚"
                    )
                    break

            st.success("å…¨è‡ªå‹•ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

        except Exception as e:
            st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã§åœæ­¢ã—ã¾ã—ãŸ: {e}")

with tab1:
    if st.button("ä½œæˆé–‹å§‹", key="start_btn"):
        session = requests.Session()
        session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 ... Chrome/91.0.4472.124"
            }
        )

        # UI Cleanup
        st.info("å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚å®Œäº†ã¾ã§ãŠå¾…ã¡ãã ã•ã„...")
        progress_bar = st.progress(0)
        log_expander = st.expander("è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º", expanded=False)
        status_area = log_expander.empty()

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        cards = []
        if os.path.exists(SAVE_FILE):
            try:
                cards = load_data_with_retry(SAVE_FILE)
            except Exception:
                pass

        try:
            # 1. ãƒªã‚¹ãƒˆãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’å–å¾—
            status_area.write(f"ãƒªã‚¹ãƒˆãƒšãƒ¼ã‚¸ã‚’å–å¾—ä¸­: {target_url}")
            resp = session.get(target_url)
            soup = BeautifulSoup(resp.text, "html.parser")

            page_title = soup.title.get_text(strip=True) if soup.title else "ä¸æ˜ãªç§‘ç›®"
            subject_name = page_title.split("-")[0]

            target_data = []

            rows = soup.find_all("tr")
            for row in rows:
                cols = row.find_all("td")
                if len(cols) >= 3:
                    level_text = cols[2].get_text(strip=True)
                    link_tag = row.find("a", href=re.compile(r"/q/\d+"))
                    if link_tag:
                        href = link_tag.get("href")
                        if "/q/" in href and re.search(r"/q/\d+/\d+/\d+/[a-e]", href):
                            full_url = urljoin(target_url, href)
                            target_data.append(
                                {
                                    "url": full_url,
                                    "level": level_text,
                                    "subject": subject_name,
                                }
                            )

            unique_data = []
            seen_urls = set()
            for d in target_data:
                if d["url"] not in seen_urls:
                    unique_data.append(d)
                    seen_urls.add(d["url"])

            st.write(f"è¦‹ã¤ã‹ã£ãŸå•é¡Œ: {len(unique_data)} ä»¶")
            targets_to_scrape = unique_data[:max_count]

            for i, item in enumerate(targets_to_scrape):
                full_link = item["url"]
                level = item["level"]
                subject = item["subject"]

                if i > 0:
                    wait_time = random.uniform(sleep_min, sleep_max)
                    status_area.write(f"å¾…æ©Ÿä¸­... ({wait_time:.1f}s)")
                    time.sleep(wait_time)

                status_area.write(
                    f"å‡¦ç†ä¸­ ({i + 1}/{len(targets_to_scrape)}): {full_link} (ãƒ©ãƒ³ã‚¯: {level})"
                )

                # 2. è©³ç´°ãƒšãƒ¼ã‚¸å–å¾—
                q_resp = session.get(full_link)
                q_soup = BeautifulSoup(q_resp.text, "html.parser")

                q_div = q_soup.find("div", class_="q_body")
                question_text = (
                    q_div.get_text(strip=True) if q_div else "å•é¡Œæ–‡å–å¾—å¤±æ•—"
                )

                q_id = None
                inputs = q_soup.find_all("input", onclick=True)
                for inp in inputs:
                    match = re.search(r"answer\((\d+),", inp["onclick"])
                    if match:
                        q_id = match.group(1)
                        break

                explanation_text = "è§£èª¬å–å¾—å¤±æ•—"
                article_text = ""
                point_text = ""

                if q_id:
                    explanation_text, article_text, point_text = get_explanation(
                        session, q_id, full_link
                    )

                # 4. ç”Ÿæˆ (AIãªã—)
                front, _ = generate_rewrite(
                    question_text, explanation_text, article_text, point_text
                )
                back = full_link

                new_card = {
                    "front": front,
                    "back": back,
                    "source": full_link,
                    "subject": subject,
                    "level": level,
                }
                try:
                    current_cards = load_data_with_retry(SAVE_FILE)
                    current_cards.append(new_card)
                    with open(SAVE_FILE, "w", encoding="utf-8") as f:
                        json.dump(current_cards, f, ensure_ascii=False, indent=2)
                    cards = current_cards
                except Exception as e:
                    st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

                progress_bar.progress((i + 1) / len(targets_to_scrape))

            status_area.success(
                f"å®Œäº†ã—ã¾ã—ãŸï¼ ãƒ‡ãƒ¼ã‚¿ã¯ {SAVE_FILE} ã«è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚"
            )

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

with tab2:
    st.header("ğŸ“‚ ä¿å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª (ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰)")
    if os.path.exists(SAVE_FILE):
        try:
            all_data = load_data_with_retry(SAVE_FILE)

            if not all_data:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
            else:
                # --- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ (ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢é…ç½®) ---
                with st.expander("ğŸ” çµã‚Šè¾¼ã¿æ¤œç´¢ (ç§‘ç›®ãƒ»é›£æ˜“åº¦)", expanded=False):
                    # 1. ç§‘ç›®ãƒ•ã‚£ãƒ«ã‚¿
                    available_subjects = sorted(
                        list(set([d.get("subject", "ä¸æ˜") for d in all_data]))
                    )
                    selected_subjects = st.multiselect(
                        "ç§‘ç›®ã§çµã‚Šè¾¼ã¿",
                        options=available_subjects,
                        default=available_subjects,
                    )

                    # 2. é›£æ˜“åº¦ãƒ•ã‚£ãƒ«ã‚¿
                    available_levels = sorted(
                        list(set([d.get("level", "ä¸æ˜") for d in all_data]))
                    )
                    selected_levels = st.multiselect(
                        "é›£æ˜“åº¦ã§çµã‚Šè¾¼ã¿",
                        options=available_levels,
                        default=available_levels,
                    )

                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ (ANDæ¡ä»¶)
                saved_data = [
                    d
                    for d in all_data
                    if d.get("level", "ä¸æ˜") in selected_levels
                    and d.get("subject", "ä¸æ˜") in selected_subjects
                ]

                # --- Ankiç”¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ (Mobileå¯¾å¿œ) ---
                st.sidebar.markdown("---")
                st.sidebar.markdown("### ğŸ“± ã‚¹ãƒãƒ›å­¦ç¿’ç”¨ (Anki)")
                if saved_data:
                    # CSVä½œæˆ (Front, Back, Tag)
                    csv_lines = []
                    for d in saved_data:
                        # æ”¹è¡Œã‚’<br>ã«ç½®æ› (Ankiä»•æ§˜)
                        f_txt = (
                            d.get("front", "").replace("\n", "<br>").replace('"', '""')
                        )
                        b_txt = (
                            d.get("back", "").replace("\n", "<br>").replace('"', '""')
                        )
                        tag = f"{d.get('subject', 'ä¸æ˜')} {d.get('level', '-')}"
                        # CSV format: "Front","Back","Tag"
                        line = f'"{f_txt}","{b_txt}","{tag}"'
                        csv_lines.append(line)

                    csv_data = "\n".join(csv_lines)

                    st.sidebar.download_button(
                        label="Ankiç”¨CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv_data.encode("utf-8-sig"),  # BOMä»˜ãUTF-8
                        file_name="anki_cards.csv",
                        mime="text/csv",
                        help="AnkiDroid(Android)ã‚„AnkiMobile(iPhone)ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ä½¿ãˆã¾ã™ã€‚æ–‡å­—åŒ–ã‘é˜²æ­¢ã®ãŸã‚BOMä»˜ãUTF-8ã§å‡ºåŠ›ã—ã¾ã™ã€‚",
                    )

                st.caption(f"å…¨ {len(all_data)} ä»¶ä¸­ã€{len(saved_data)} ä»¶ã‚’è¡¨ç¤ºä¸­")

                # --- è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ ---
                view_mode = st.radio(
                    "è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰",
                    ["ã‚«ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ (1æšãšã¤)", "ä¸€è¦§è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ (ãƒªã‚¹ãƒˆ)"],
                    horizontal=True,
                )

                if view_mode == "ã‚«ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ (1æšãšã¤)":
                    if not saved_data:
                        st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ã‚«ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    else:
                        # --- Session State åˆæœŸåŒ– ---
                        if "card_idx" not in st.session_state:
                            st.session_state.card_idx = 0
                        if "is_flipped" not in st.session_state:
                            st.session_state.is_flipped = False

                        # ç¯„å›²ãƒã‚§ãƒƒã‚¯
                        if st.session_state.card_idx >= len(saved_data):
                            st.session_state.card_idx = 0

                        # ç¾åœ¨ã®ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        card = saved_data[st.session_state.card_idx]

                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
                        subject_info = card.get("subject", "ä¸æ˜")
                        level_info = card.get("level", "-")

                        front_text = card["front"]
                        back_text = card["back"]
                        # source_url = card.get("source", "")

                        # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        if (
                            front_text.startswith("AIç”Ÿæˆã‚¨ãƒ©ãƒ¼")
                            or "AIç”Ÿæˆã‚¨ãƒ©ãƒ¼" in front_text
                        ):
                            pass

                        # --- ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
                        # ãƒ˜ãƒƒãƒ€ãƒ¼ã«ç§‘ç›®ã¨ãƒ¬ãƒ™ãƒ«ã‚’è¡¨ç¤º
                        st.markdown(f"#### ğŸ·ï¸ {subject_info} / ãƒ©ãƒ³ã‚¯: {level_info}")
                        st.markdown(
                            f"**No. {st.session_state.card_idx + 1} / {len(saved_data)}**"
                        )

                        new_index = st.slider(
                            "ã‚«ãƒ¼ãƒ‰ç§»å‹•",
                            min_value=1,
                            max_value=len(saved_data),
                            value=st.session_state.card_idx + 1,
                            label_visibility="collapsed",
                        )
                        # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼æ“ä½œã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¤‰æ›´
                        if new_index - 1 != st.session_state.card_idx:
                            st.session_state.card_idx = new_index - 1
                            st.session_state.is_flipped = False
                            st.rerun()

                        # ã‚«ãƒ¼ãƒ‰è¡¨ç¤ºã‚¨ãƒªã‚¢
                        card_container = st.container(border=True)
                        with card_container:
                            if st.session_state.is_flipped:
                                st.markdown("### ğŸ’¡ ã‚½ãƒ¼ã‚¹URL (è£é¢)")
                                st.code(back_text, language=None)
                                st.link_button("å…ƒã‚µã‚¤ãƒˆã‚’é–‹ã", back_text)
                            else:
                                st.markdown("### ğŸ“ ã‚«ãƒ¼ãƒ‰å†…å®¹ (è¡¨é¢)")
                                st.markdown(front_text)

                        # æ“ä½œãƒœã‚¿ãƒ³ (3ã‚«ãƒ©ãƒ )
                        col_prev, col_flip, col_next = st.columns([1, 2, 1])

                        with col_prev:
                            if st.button("â¬…ï¸ å‰ã¸"):
                                st.session_state.card_idx = max(
                                    0, st.session_state.card_idx - 1
                                )
                                st.session_state.is_flipped = False
                                st.rerun()

                        with col_flip:
                            button_label = "ç­”ãˆã‚’è¦‹ã‚‹ / æˆ»ã‚‹ ğŸ”„"
                            if st.button(button_label, use_container_width=True):
                                st.session_state.is_flipped = (
                                    not st.session_state.is_flipped
                                )
                                st.rerun()

                        with col_next:
                            if st.button("æ¬¡ã¸ â¡ï¸"):
                                st.session_state.card_idx = min(
                                    len(saved_data) - 1, st.session_state.card_idx + 1
                                )
                                st.session_state.is_flipped = False
                                st.rerun()

                else:
                    # --- ä¸€è¦§è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ ---
                    st.markdown("---")

                    if not saved_data:
                        st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    else:
                        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
                        items_per_page = 50
                        total_pages = (len(saved_data) - 1) // items_per_page + 1

                        if "list_page" not in st.session_state:
                            st.session_state.list_page = 1

                        # ãƒšãƒ¼ã‚¸é¸æŠ (ä¸Šéƒ¨)
                        col_p1, col_p2 = st.columns([2, 1])
                        with col_p1:
                            st.markdown(
                                f"**å…¨ {len(saved_data)} ä»¶ä¸­ã€{items_per_page} ä»¶ãšã¤è¡¨ç¤º**"
                            )
                        with col_p2:
                            st.session_state.list_page = st.number_input(
                                "ãƒšãƒ¼ã‚¸ç•ªå·",
                                min_value=1,
                                max_value=total_pages,
                                value=st.session_state.list_page,
                            )

                        start_idx = (st.session_state.list_page - 1) * items_per_page
                        end_idx = min(start_idx + items_per_page, len(saved_data))

                        current_batch = saved_data[start_idx:end_idx]

                        for i, d in enumerate(current_batch):
                            global_idx = start_idx + i + 1
                            subject = d.get("subject", "ä¸æ˜")
                            level = d.get("level", "-")
                            front = d.get("front", "")
                            back_url = d.get("back", "")  # backã¯URLãŒå…¥ã£ã¦ã„ã‚‹å‰æ

                            # å•é¡Œæ–‡ã®ï¼‘è¡Œç›®ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã«ã™ã‚‹ï¼ˆé•·ã™ããŸã‚‰ã‚«ãƒƒãƒˆï¼‰
                            title_line = front.split("\n")[0]
                            if len(title_line) > 30:
                                title_line = title_line[:30] + "..."

                            label = f"No.{global_idx} [{subject}] {title_line}"

                            with st.expander(label):
                                st.markdown("#### ğŸ“ å•é¡Œ")
                                st.text(
                                    front
                                )  # Markdownã ã¨å´©ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§textæ¨å¥¨ã ãŒã€è¦ä»¶æ¬¡ç¬¬ã€‚ä¸€æ—¦textã§ã€‚
                                st.markdown("---")
                                st.markdown("#### ğŸ’¡ è§£èª¬ãƒ»ãƒªãƒ³ã‚¯")
                                st.write(f"ãƒ©ãƒ³ã‚¯: {level}")
                                st.link_button(
                                    f"ğŸ”— å…ƒã‚µã‚¤ãƒˆã‚’é–‹ã ({back_url})", back_url
                                )

                        # ãƒšãƒ¼ã‚¸é¸æŠ (ä¸‹éƒ¨)
                        st.markdown("---")
                        if total_pages > 1:
                            st.success(
                                f"ç¾åœ¨: {st.session_state.list_page} / {total_pages} ãƒšãƒ¼ã‚¸"
                            )

        except Exception as e:
            st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        st.info(
            "ã¾ã ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œã€ã‚¿ãƒ–ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        )
