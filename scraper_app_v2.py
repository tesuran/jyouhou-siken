import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import os

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ»ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼", page_icon="ğŸ•·ï¸", layout="wide")

st.title("ğŸ•·ï¸ ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ»ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ (Rate Limitå¯¾ç­–ç‰ˆ)")
st.markdown("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€**ã‚µãƒ¼ãƒãƒ¼ã¸ã®è² è·ã‚’æœ€å°é™ã«æŠ‘ãˆãªãŒã‚‰**ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
ãƒ©ãƒ³ãƒ€ãƒ ãªå¾…æ©Ÿæ™‚é–“ã‚’è¨­ã‘ã‚‹ã“ã¨ã§ã€Botæ¤œçŸ¥ã‚„ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ã®ãƒªã‚¹ã‚¯ã‚’ä½æ¸›ã—ã¾ã™ã€‚
""")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("âš™ï¸ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š")

# 1. URLè¨­å®š
input_method = st.sidebar.radio(
    "URLå…¥åŠ›æ–¹æ³•", ["å˜ä¸€URL", "URLãƒªã‚¹ãƒˆ(æ”¹è¡ŒåŒºåˆ‡ã‚Š)", "é€£ç•ªURLç”Ÿæˆ"]
)

target_urls = []

if input_method == "å˜ä¸€URL":
    url = st.sidebar.text_input("å¯¾è±¡URL", "https://example.com")
    if url:
        target_urls = [url]

elif input_method == "URLãƒªã‚¹ãƒˆ(æ”¹è¡ŒåŒºåˆ‡ã‚Š)":
    urls_text = st.sidebar.text_area(
        "URLãƒªã‚¹ãƒˆ", "https://example.com/page1\nhttps://example.com/page2"
    )
    if urls_text:
        target_urls = [u.strip() for u in urls_text.split("\n") if u.strip()]

elif input_method == "é€£ç•ªURLç”Ÿæˆ":
    base_url = st.sidebar.text_input(
        "ãƒ™ãƒ¼ã‚¹URL (ç•ªå·éƒ¨åˆ†ã‚’ {} ã«ã—ã¦ãã ã•ã„)", "https://example.com/page/{}"
    )
    start_num = st.sidebar.number_input("é–‹å§‹ç•ªå·", 1, 1000, 1)
    end_num = st.sidebar.number_input("çµ‚äº†ç•ªå·", 1, 1000, 5)
    if base_url:
        target_urls = [base_url.format(i) for i in range(start_num, end_num + 1)]

st.sidebar.write(f"å¯¾è±¡URLä»¶æ•°: **{len(target_urls)}** ä»¶")

# 2. æŠ½å‡ºãƒ«ãƒ¼ãƒ«
st.sidebar.subheader("æŠ½å‡ºãƒ«ãƒ¼ãƒ« (CSSã‚»ãƒ¬ã‚¯ã‚¿)")
selector_container = st.sidebar.text_input(
    "ã‚³ãƒ³ãƒ†ãƒŠ (å„ã‚¢ã‚¤ãƒ†ãƒ ã‚’å›²ã‚€è¦ç´ )", "div.article"
)
selector_title = st.sidebar.text_input("ã‚¿ã‚¤ãƒˆãƒ«/è³ªå•", "h2.title")
selector_content = st.sidebar.text_input("å†…å®¹/ç­”ãˆ", "div.content")

# 3. å¾…æ©Ÿè¨­å®šï¼ˆé‡è¦ï¼‰
st.sidebar.subheader("â±ï¸ å¾…æ©Ÿè¨­å®š (Safety)")
min_sleep = st.sidebar.slider("æœ€å°å¾…æ©Ÿæ™‚é–“ (ç§’)", 1.0, 10.0, 3.0)
max_sleep = st.sidebar.slider("æœ€å¤§å¾…æ©Ÿæ™‚é–“ (ç§’)", 5.0, 30.0, 10.0)

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

if st.button("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹", type="primary"):
    if not target_urls:
        st.error("URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()

        # User-Agentã®è¨­å®šï¼ˆé‡è¦ï¼‰
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        stop_button = st.button("ä¸­æ–­")

        for i, url in enumerate(target_urls):
            if stop_button:
                st.warning("å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚")
                break

            # 1. ãƒ©ãƒ³ãƒ€ãƒ Wait (åˆå›ä»¥å¤–)
            if i > 0:
                sleep_time = random.uniform(min_sleep, max_sleep)
                status_text.write(f"â³ å¾…æ©Ÿä¸­... ({sleep_time:.2f}ç§’)")
                time.sleep(sleep_time)

            # 2. ã‚¢ã‚¯ã‚»ã‚¹
            try:
                status_text.write(f"ğŸ”„ ã‚¢ã‚¯ã‚»ã‚¹ä¸­ ({i + 1}/{len(target_urls)}): {url}")
                response = requests.get(url, headers=headers, timeout=10)
                response.raise_for_status()  # ã‚¨ãƒ©ãƒ¼ãªã‚‰ä¾‹å¤–ç™ºç”Ÿ

                # 3. è§£æ
                soup = BeautifulSoup(response.content, "html.parser")

                # ã‚³ãƒ³ãƒ†ãƒŠå˜ä½ã§æ¢ã™ã‹ã€å˜ä¸€ãƒšãƒ¼ã‚¸ã‹ã‚‰æ¢ã™ã‹
                containers = soup.select(selector_container)

                if containers:
                    for item in containers:
                        title_elm = item.select_one(selector_title)
                        content_elm = item.select_one(selector_content)

                        title_text = (
                            title_elm.get_text(strip=True) if title_elm else "N/A"
                        )
                        content_text = (
                            content_elm.get_text(strip=True) if content_elm else "N/A"
                        )

                        results.append(
                            {"URL": url, "Title": title_text, "Content": content_text}
                        )
                else:
                    # ã‚³ãƒ³ãƒ†ãƒŠãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ãƒšãƒ¼ã‚¸å…¨ä½“ã‹ã‚‰1ã¤æ¢ã™ï¼ˆè©³ç´°ãƒšãƒ¼ã‚¸ãªã©ã®å ´åˆï¼‰
                    title_elm = soup.select_one(selector_title)
                    content_elm = soup.select_one(selector_content)

                    if title_elm or content_elm:
                        results.append(
                            {
                                "URL": url,
                                "Title": title_elm.get_text(strip=True)
                                if title_elm
                                else "N/A",
                                "Content": content_elm.get_text(strip=True)
                                if content_elm
                                else "N/A",
                            }
                        )
                    else:
                        st.warning(f"ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {url}")

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ ({url}): {e}")

            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°
            progress_bar.progress((i + 1) / len(target_urls))

        status_text.text("âœ… å®Œäº†ã—ã¾ã—ãŸï¼")

        # çµæœè¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        if results:
            df = pd.DataFrame(results)
            st.success(f"{len(results)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
            st.dataframe(df)

            csv = df.to_csv(index=False).encode("utf-8_sig")
            st.download_button(
                label="CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name="scraped_data.csv",
                mime="text/csv",
            )
        else:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚»ãƒ¬ã‚¯ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

with st.expander("ä½¿ã„æ–¹"):
    st.markdown("""
    1. **URLå…¥åŠ›**: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã—ãŸã„URLã‚’æŒ‡å®šã—ã¾ã™ã€‚é€£ç•ªã®å ´åˆã¯ `https://site.com/page/{}` ã®ã‚ˆã†ã« `{}` ã‚’ä½¿ã„ã¾ã™ã€‚
    2. **ã‚»ãƒ¬ã‚¯ã‚¿è¨­å®š**: Chromeã®æ¤œè¨¼ãƒ„ãƒ¼ãƒ«(F12)ãªã©ã§ã€å–å¾—ã—ãŸã„è¦ç´ ã®CSSã‚»ãƒ¬ã‚¯ã‚¿ã‚’èª¿ã¹ã¾ã™ã€‚
       - `div.class_name` ã‚„ `#id_name` ãªã©
    3. **å¾…æ©Ÿè¨­å®š**: ã‚µã‚¤ãƒˆã®è² è·ã‚’è€ƒãˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(3~10ç§’)ä»¥ä¸Šã®æ™‚é–“ã‚’è¨­å®šã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
    4. **å®Ÿè¡Œ**: é–‹å§‹ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ã‚†ã£ãã‚Šã¨ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¾ã™ã€‚
    """)
